# ğŸ–¥ï¸ CGCNN hands-on tutorial
CGCNNì€ Jeffrey C. Grossman êµìˆ˜ë‹˜ê³¼ Tian Xie ë°•ì‚¬ë‹˜ì´ ê°œë°œí•œ ì†Œì¬ ë¬¼ì„± ì˜ˆì¸¡ìš© ê·¸ë˜í”„ ì‹ ê²½ë§ ëª¨ë¸ë¡œ, ì´ë¡ ì  ë°°ê²½ì€ ë‹¤ìŒ ë…¼ë¬¸ì— ìì„¸íˆ ì„¤ëª…ë˜ì–´ ìˆë‹¤.

- T. Xie and J. C. Grossman, *Crystal graph convolutional neural networks for an accurate and interpretable prediction of material properties*, Physical Review Letters 120,145301 (2018). [Article](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.120.145301)


í•´ë‹¹ ë…¼ë¬¸ì—ì„œ ì œê³µí•˜ê³  ìˆëŠ” ëª¨ë¸ì˜ ì‹¤ìŠµ ì½”ë“œëŠ” [txie-93/github](https://github.com/txie-93/cgcnn?tab=readme-ov-file)ì—ì„œ ë‹¤ìš´ë°›ì„ ìˆ˜ ìˆë‹¤.

ë‹¤ë§Œ, í•´ë‹¹ GitHubì—ì„œ ì œê³µí•˜ëŠ” ë°ì´í„°ì…‹ì€ ê·œëª¨ê°€ ë§¤ìš° ì‘ì•„ ëª¨ë¸ í•™ìŠµ ê²°ê³¼ë¥¼ ì‹ ë¢°í•˜ê¸° ì–´ë µê³ , ì‹¤ì œ ì‘ìš© ì—°êµ¬ì— í™œìš©í•˜ê¸°ì—ë„ í•œê³„ê°€ ìˆë‹¤.
ì´ëŸ¬í•œ ì œì•½ì„ ë³´ì™„í•˜ê¸° ìœ„í•´ KIST ê¹€ë™í›ˆ ë°•ì‚¬ë‹˜ì€ ê¸°ì¡´ GitHub ì½”ë“œì— ìƒˆë¡œìš´ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ê³¼ ë³´ì¡° ê¸°ëŠ¥ì„ ì¶”ê°€í•œ [Google Drive](https://drive.google.com/drive/folders/1HbxgZYCAJWynwFCwgWxfeg4-SrlWs0Gm) ìë£Œë¥¼ ì œê³µí•˜ê³  ìˆìœ¼ë©°, ë³¸ ì‹¤ìŠµì—ì„œëŠ” ì´ë¥¼ í™œìš©í•˜ì—¬ ë³´ë‹¤ ì‹¤ì œì ì¸ ëª¨ë¸ í•™ìŠµê³¼ í‰ê°€ë¥¼ ì§„í–‰í•œë‹¤.

ì´ íŠœí† ë¦¬ì–¼ì€ ìƒë‹¨ì˜ datasetì„ ê°€ì§€ê³  ì§„í–‰í•œ CGCNN ì‹¤ìŠµì„ step-by-stepìœ¼ë¡œ ë‚˜íƒ€ë‚¸ ê²ƒì´ë‹¤.
Google Driveì˜ ë°ì´í„°ë¥¼ ì „ë¶€ ë‹¤ìš´ë¡œë“œ í›„, ì••ì¶• í•´ì œí•˜ë©´ ëœë‹¤. 

--------------------

# ğŸ“‘ Table of Contents

- [í”„ë¡œê·¸ë¨ ì„¤ì¹˜ ë° í™˜ê²½ì„¤ì •](#-----------------)

- [ì½”ë“œ Framework](#------framework)
    + [input íŒŒì¼](#---input---)
    + [ëª¨ë¸ ë™ì‘ íŒŒì¼](#-------------py----)
    + [output íŒŒì¼](#---output---)
    + [ê° í´ë” ì„¤ëª…](#----------)
- [ê°ì¢… parameter ì¡°ì ˆë²•](#------parameter----)
    + [hyperparameter](#---hyperparameter)
    + [node feature vector](#---node-feature-vector)
    + [edge feature vector](#---edge-feature-vector)
- [Training by txie-93 github dataset](#---training-by-txie-93-github-dataset)
- [Predicting by txie-93 github dataset](#---predicting-by-txie-93-github-dataset)
- [Training by google drive dataset](#---training-by-google-drive-dataset)

--------------------

## ğŸ“Œ í”„ë¡œê·¸ë¨ ì„¤ì¹˜ ë° í™˜ê²½ì„¤ì •
**CGCNN ì‹¤ìŠµì€ Condaë¥¼ ì´ìš©í•´ ì§„í–‰ëœë‹¤. 
ìš°ì„  [Conda ì„¤ì¹˜](https://docs.conda.io/en/latest/) í›„ ìµœì‹  ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸ í•˜ê³ , ê°€ìƒí™˜ê²½ì„ ë§Œë“¤ì–´ì¤€ ë’¤ ê·¸ ì•ˆì— PyTorch, scikit-learn, pymatgenì´ë¼ëŠ” ì„¸ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•  ê²ƒì´ë‹¤.**


### **1. conda ì—…ë°ì´íŠ¸**

condaê°€ ìµœì‹ ë²„ì „ì´ ì•„ë‹ˆë¼ë©´, íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹œ ì—ëŸ¬ê°€ ëœ° ìˆ˜ë„ ìˆë‹¤.
anaconda prompt í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰ì‹œì¼œì¤€ í›„, ë‹¤ìŒì²˜ëŸ¼ ì…ë ¥í•˜ì—¬ condaë¥¼ ìµœì‹  ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸ ì‹œì¼œì¤€ë‹¤.
~~~
conda update -n base -c defaults conda
~~~
ë§Œì¼ ì—…ë°ì´íŠ¸ë¥¼ í–ˆìŒì—ë„ ìê¾¸ 
~~~
WARNING: A newer version of conda exists.
current version: 25.5.1
latest version: 25.7.0
~~~
ì²˜ëŸ¼ ëœ¬ë‹¤ë©´, 
~~~
conda update conda --all
~~~
ì„ ì…ë ¥í•˜ì—¬ í•´ê²°í•  ìˆ˜ ìˆë‹¤.


ì œëŒ€ë¡œ ì—…ë°ì´íŠ¸ ë˜ì—ˆëŠ”ì§€ëŠ”
~~~
conda --version
~~~
ì„ ì…ë ¥í–ˆì„ ë•Œ ìµœì‹  ë²„ì „ìœ¼ë¡œ ëœ¨ëŠ”ì§€ í™•ì¸í•˜ë©´ ëœë‹¤.


### **2. ê°€ìƒí™˜ê²½ ìƒì„± í›„ ê·¸ ì•ˆì— íŒ¨í‚¤ì§€ ì„¤ì¹˜**

conda ì „ì²´ê°€ ì•„ë‹ˆë¼ ì‹¤ìŠµì„ ì§„í–‰í•  í™˜ê²½ì—ë§Œ PyTorch, scikit-learn, pymatgenë¥¼ ì„¤ì¹˜í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì´ ìƒˆë¡œìš´ ê°€ìƒ í™˜ê²½ì„ ë§Œë“¤ì–´ì¤€ë‹¤. 

í™˜ê²½ ì´ë¦„ì€ ì›í•˜ëŠ” ëŒ€ë¡œ ì§€ì–´ì£¼ë©´ ëœë‹¤. ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” 'cgcnn'ì´ë¼ëŠ” ì´ë¦„ì„ ë¶™ì¸ ê°€ìƒí™˜ê²½ì„ ë§Œë“¤ ê²ƒì´ë‹¤.
~~~
conda create -n cgcnn
~~~
ê¸°ë³¸í™˜ê²½ì¸ (base) ëŒ€ì‹  ìƒˆë¡œ ìƒì„±ëœ (cgcnn)ì´ë¼ëŠ” ê°€ìƒ í™˜ê²½ì„ í™œì„±í™” ì‹œì¼œì¤€ í›„,
~~~
conda activate cgcnn
~~~

ë‹¤ìŒê³¼ ê°™ì´ ì„¸ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì¤€ë‹¤.
ì´ë•Œ, pipì€ íŒŒì´ì¬ìœ¼ë¡œ ì‘ì„±ëœ íŒ¨í‚¤ì§€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ê³  ê´€ë¦¬í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ëª…ë ¹ì–´ì´ë‹¤.
~~~
# PyTorch ì„¤ì¹˜
pip install torch

# scikit-learn ì„¤ì¹˜
pip install scikit-learn

# Pymatgen ì„¤ì¹˜
pip install pymatgen
~~~
`pip list`ë¥¼ ì…ë ¥í–ˆì„ ë•Œ, ë¦¬ìŠ¤íŠ¸ì— ì„¸ íŒ¨í‚¤ì§€ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ ì„±ê³µì ìœ¼ë¡œ ì„¤ì¹˜ëœ ê²ƒì´ë‹¤.

ì´ì œ êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ ë‹¤ìš´ë°›ì•˜ë˜ íŒŒì¼ì´ ìˆëŠ” ê²½ë¡œë¡œ ì´ë™í•´ì¤˜ì•¼ í•œë‹¤.
ì»´í“¨í„° ìƒì—ì„œ êµ¬ê¸€ ë“œë¼ì´ë¸Œ í´ë”ë¥¼ ìš°í´ë¦­ í•˜ê³  ì†ì„±ì— ë“¤ì–´ê°€ë©´, ë‹¤ìŒê³¼ ê°™ì´ íŒŒì¼ ê²½ë¡œê°€ ë‚˜ì˜¨ë‹¤.

~~~
C:\Users\ingyeong\Desktop\Summer
~~~

conda ë‚´ì—ì„œ ì´ íŒŒì¼ì— ì ‘ê·¼í•˜ê¸° ìœ„í•´, promptì— ë‹¤ìŒê³¼ ê°™ì´ ê²½ë¡œë¥¼ ì…ë ¥í•´ì¤€ë‹¤.
~~~
cd Desktop/Summer/cgcnn-master
~~~

ë‹¤ìš´ë°›ì•˜ë˜ íŒŒì¼ì´ ìˆëŠ” ê²½ë¡œì— ë“¤ì–´ê°„ í›„, ê·¸ í´ë” ì•ˆì— ìˆë˜ ì½”ë“œì¸ main.pyë¥¼ ì‹œí—˜ì‚¼ì•„ ì‹¤í–‰ì‹œì¼œ ë´¤ì„ ë•Œ 
~~~
python main.py -h
~~~
ë‹¤ìŒê³¼ ê°™ì´ option ëª©ë¡ì´ ì­‰ ëœ¬ë‹¤ë©´ ì‹¤ìŠµì„ ìœ„í•œ í™˜ê²½ì„¤ì •ì´ ëë‚œ ê²ƒì´ë‹¤.
~~~
usage: main.py [-h] [--task {regression, classification}]
.
.
~~~

## ğŸ“Œ ì½”ë“œ Framework

íŒŒì¼ì€ ì„œë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê´€ê³„ë¥¼ ê°€ì§€ë©° ì‘ë™í•œë‹¤. ê° íŒŒì¼ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì€ í•˜ë‹¨ì— ê¸°ìˆ í•˜ì˜€ë‹¤. 

<img width="1578" height="869" alt="image" src="https://github.com/user-attachments/assets/bd64c46a-0b35-402d-943c-1982a24f756d" />


1) í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ë° input íŒŒì¼ êµ¬ì„±í•˜ê¸°
2) `main.py` ì‹¤í–‰ì‹œí‚¤ë©´ `id_prop.csv`ë¥¼ ì½ì–´ ì²« ë²ˆì§¸ ì—´ì¸ idì˜ ëª©ë¡ì„ ì–»ê²Œ ë¨.
3) `data.py`ë¥¼ í˜¸ì¶œí•˜ì—¬ `main.py`ì—ì„œ ì½ì–´ë‚¸ id ëª©ë¡ì„ `data.py`ë¡œ ë„˜ê¹€. `data.py`ëŠ” ë°›ì€ id ëª©ë¡ì— í•´ë‹¹í•˜ëŠ” `id.cif` íŒŒì¼ì„ ì°¾ìŒ.
4) `id.cif`ìœ¼ë¡œë¶€í„° ì–»ì€ ê²°ì •êµ¬ì¡°ëŠ” `atom_init.json` íŒŒì¼ì„ ë°”íƒ•ìœ¼ë¡œ ë²¡í„°í™”ëœ ê·¸ë˜í”„ í˜•íƒœë¡œ ë‚˜íƒ€ë‚´ì–´ì§.
5) `data.py`ì—ì„œ ë²¡í„°í™”ëœ ê·¸ë˜í”„ëŠ” ë‹¤ì‹œ `main.py`ë¡œ ë°˜í™˜ë¨. ì´í›„ `id_prop.csv`ì— ë”°ë¼ ë²¡í„°í™”ëœ ê²°ì •êµ¬ì¡° ê·¸ë˜í”„ì™€ ë¬¼ì„±ì´ ë§¤ì¹­ë¨.
6) `main.py`ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ ë²¡í„°í™”ëœ ê·¸ë˜í”„ ë°ì´í„°ë¥¼ `model.py`ë¡œ ì „ì†¡.
7) `model.py`ëŠ” ëª¨ë¸ì˜ CNN êµ¬ì¡°ë¥¼ êµ¬ì¶•í•œ í›„ì— ë‹¤ì‹œ `main.py`ë¡œ ë°˜í™˜.
8) ì •í•´ì§„ epoch íšŸìˆ˜ë§Œí¼ `main.py`ì„ í†µí•´ í›ˆë ¨ í›„, í›ˆë ¨ ê²°ê³¼ ë°ì´í„° ìƒì„±ë¨.
9) í›ˆë ¨ëœ ëª¨ë¸ì„ ê°€ì§€ê³  `predict.py` ì§„í–‰ ì‹œ, ì˜ˆì¸¡ ê²°ê³¼ ë°ì´í„° ìƒì„±ë¨.

------------------------

### ğŸ”· input íŒŒì¼

Trainingê³¼ Predictingì„ ìœ„í•´ CGCNN ëª¨ë¸ì— ë°ì´í„°ë¥¼ ì…ë ¥í•˜ë ¤ë©´, ìš°ì„  í•„ìš”í•œ ë°ì´í„°ë“¤ì„ í•˜ë‚˜ì˜ í´ë”ë¡œ ë¬¶ì–´ì•¼ í•œë‹¤. (customized dataset)

ì‹¤ìŠµ íŒŒì¼ ì¤‘ì—ì„œëŠ” sample-classificationê³¼ sample-regressionì´ customized datasetì— í•´ë‹¹í•œë‹¤.

ëª¨ë¸ì— inputìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” customized datasetì—ëŠ” ë‹¤ìŒ íŒŒì¼ë“¤ì´ í¬í•¨ë˜ì–´ì•¼ í•œë‹¤.


- `id_prop.csv` : idì™€ propertyë¥¼ ë¬¶ì€ csv íŒŒì¼ë¡œ 1ì—´ì—ëŠ” id, 2ì—´ì—ëŠ” propertyê°€ ì í˜€ìˆë‹¤.
  
    - `id` : ê° ê²°ì •êµ¬ì¡°ë§ˆë‹¤ ë²ˆí˜¸ë¥¼ ë¶€ì—¬í•´ì¤€ ê²ƒ. (ex. cubic êµ¬ì¡°ì˜ SiO2 idëŠ” 8352)
  
    - `property` : ë¬¼ì„±ê°’(ex. bandgap, formation energy)ì„ ì˜ë¯¸.

       (Training ì‹œ)  ì¬ë£Œì˜ ì‹¤ì œ ë¬¼ì„±ê°’ì„ ì…ë ¥í•´ì¤˜ì•¼ í•œë‹¤.
      
       (Predicting ì‹œ) ëª¨ë¸ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ê²½ìš°ì—ëŠ” ì‹¤ì œ ë¬¼ì„±ê°’ì„ ì…ë ¥í•´ì£¼ì–´ì•¼ í•œë‹¤.

      ì˜ˆì¸¡ë§Œ í•˜ëŠ” ê²½ìš°ì—ëŠ” ì‹¤ì œ ë¬¼ì„±ê°’ì´ í•„ìš” ì—†ìœ¼ë‚˜, 2ì—´ì„ ë¹„ì›Œë‘˜ ì‹œ ì½”ë“œê°€ íŒŒì¼ì„ ì œëŒ€ë¡œ ì½ì§€ ëª»í•˜ë¯€ë¡œ ì•„ë¬´ ìˆ«ì(dummy)ë¥¼ ë„£ì–´ì„œ í˜•ì‹ì„ ë§ì¶°ì£¼ì–´ì•¼ í•œë‹¤.     
  
- `id.cif` : ê²°ì •êµ¬ì¡°ì— ëŒ€í•œ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” íŒŒì¼ë¡œ, ê²°ì •ì˜ ë¬¼ë¦¬ì  íŠ¹ì„±, ì¢Œí‘œ, ê²©ì ë“±ì— ê´€í•œ ì •ë³´ë¥¼ ì•Œë ¤ì¤€ë‹¤.

   MPì—ì„œ ì œê³µí•˜ëŠ” ê²°ì •êµ¬ì¡° íŒŒì¼ì€ 'mp-id.cif' í˜•íƒœë¡œ ì œê³µëœë‹¤. (ex. mp-13, mp-241)

   ë‹¨ì§€ ìš°ë¦¬ê°€ inputìœ¼ë¡œ í™œìš©í•˜ëŠ” ë°ì´í„°ì¸ 'id_prop.csv'ì˜ ì²« ì—´ê³¼ cifì˜ íŒŒì¼ëª…ì„ ì¼ì¹˜ì‹œí‚¤ê¸° ìœ„í•´ 'id.cif'ë¡œ ë°”ê¿”ì„œ ì €ì¥í•˜ëŠ” ê²ƒì´ë‹¤.
  
  
- `atom_init.json` : ì›ì†Œë¥¼ ìˆ«ìë¡œ í‘œí˜„í•˜ê¸° ìœ„í•œ ì´ˆê¸° ë²¡í„° ë°ì´í„°ë¡œ, ì£¼ê¸°ìœ¨í‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê° ì›ì†Œì— ëŒ€í•œ íŠ¹ì„±ì´ one-hot encoding ëœ í˜•íƒœë¡œ ì •ë¦¬ë˜ì–´ ìˆë‹¤.

  ì‰½ê²Œ ë§í•´ SiëŠ” ë²¡í„°ë¡œ [ìˆ«ì, , , ..], NaëŠ” ë²¡í„°ë¡œ [ìˆ«ì, , , ..]ì™€ ê°™ì´ ë³€í™˜í•˜ë¼ê³  ì•Œë ¤ì£¼ëŠ” ì°¸ê³ ìš© ë¬¸ì„œì´ë‹¤.
  

### ğŸ”· ëª¨ë¸ ë™ì‘ íŒŒì¼ (.py íŒŒì¼)

`.py` íŒŒì¼ì€ ë§ˆì¹˜ ë ˆì‹œí”¼ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤. ìš°ë¦¬ê°€ ë ˆì‹œí”¼ë¥¼ ë³´ê³  ìš”ë¦¬í•˜ë“¯ì´, `.py` íŒŒì¼ì˜ ì½”ë“œë¥¼ ì‹¤í–‰ì‹œí‚´ìœ¼ë¡œì¨ ëª¨ë¸ì„ ì‘ë™ì‹œí‚¤ëŠ” ê²ƒì´ë‹¤.

- `main.py` : ê²°ì •êµ¬ì¡°(id)ë¥¼ inputìœ¼ë¡œ ë°›ì•„ ë¬¼ì„±(property)ì„ outputìœ¼ë¡œ ë‚´ë†“ëŠ” CGCNNì˜ í•µì‹¬ ë™ì‘ íŒŒì¼ë¡œ, `data.py`ì™€ `model.py`ë¥¼ ì—°ê²°í•´ train/predictë¥¼ ìˆ˜í–‰í•œë‹¤.
  
- `data.py` : idë¥¼ inputìœ¼ë¡œ ë°›ì•„ ë²¡í„°í™”ëœ ê·¸ë˜í”„ë¥¼ outputìœ¼ë¡œ ë‚´ë†“ëŠ”ë‹¤.
  
  ì…ë ¥ë°›ì€ idì— í•´ë‹¹í•˜ëŠ” ê²°ì •êµ¬ì¡°(.cif)ë¥¼ ë°›ì•„ì˜¤ëŠ” ì§€ì ê³¼, ê²°ì •êµ¬ì¡°ë¥¼ ë³´ê³  ë²¡í„°í™”ì‹œí‚¤ëŠ” ì§€ì (atom_init.json)ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.
   
- `model.py` : pyTorchë¥¼ ì´ìš©í•´ graph convolutional network êµ¬ì¡°ë¥¼ ì •ì˜í•´ì¤€ë‹¤.
- `predict.py` : ì™„ì„±ëœ ëª¨ë¸ì„ ì´ìš©í•´ ë¬¼ì„±ì„ ì˜ˆì¸¡í•œë‹¤.
- `draw_graph.py` : í•™ìŠµ/ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ê·¸ë˜í”„ë¡œ ë‚˜íƒ€ë‚´ì¤€ë‹¤.

### ğŸ”· output íŒŒì¼
- Training ê²°ê³¼ íŒŒì¼
  - `checkpoint.pth.tar` : í•™ìŠµ ì¤‘ê°„ ì €ì¥ìš© íŒŒì¼ë¡œ, ë§ˆì§€ë§‰ epoch ëª¨ë¸ ì €ì¥.
  - `model_best.pth.tar` : validation accuracyê°€ ê°€ì¥ ë†’ì•˜ë˜ ëª¨ë¸ ì €ì¥.
  - `epoch_loss.csv` : ê° epoch ë§ˆë‹¤ì˜ í›ˆë ¨ lossê°’ ê¸°ë¡.
  - `train_result.csv`, `validation_result.csv`, `test_result.csv` : train/validation/test setì—ì„œì˜ ê° ìƒ˜í”Œë³„ ì˜ˆì¸¡ ê²°ê³¼ ê¸°ë¡.
  - `draw_graph.py` ì‹¤í–‰ ì‹œ `epoch_loss.png`, `target_pred_test/train/validation.png` íŒŒì¼ ìƒì„±ë¨.
    
- Prediction ê²°ê³¼ íŒŒì¼
  - `test_result.csv` : test setìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²°ê³¼ë¥¼ ê¸°ë¡í•œ íŒŒì¼ë¡œ ê° ê²°ì •ì˜ ID, ëª©í‘œê°’(id_prop.csv íŒŒì¼ì—ì„œ ë„£ì–´ì¤€ prop ê°’), ì˜ˆì¸¡ê°’(CGCNNì´ ì˜ˆì¸¡í•œ ê°’) ì €ì¥.

### ğŸ”· ê° í´ë” ì„¤ëª…
- `data` : MPì—ì„œ ê°€ì ¸ì˜¨ train & predictë¥¼ ìœ„í•œ ë°ì´í„° í¬í•¨.
  - `sample-classification`, `sample-regression` : trainingì„ ìœ„í•œ sample customized dataset.

  - `data_classification/regression_` : ê° ë¬¼ì„±ê°’ì„ í›ˆë ¨í•˜ê¸° ìœ„í•œ ë°ì´í„°ì…‹.
    
- `node_vector_generation` : node feature vector ìˆ˜ì •ì„ ìœ„í•œ íŒŒì¼ í¬í•¨.
   
- `pre-trained` : ë…¼ë¬¸ì—ì„œ ë‹¤ë£¨ê³  ìˆëŠ” pre-trained ëª¨ë¸ì— ëŒ€í•œ data í¬í•¨.
  
- `result` : `data` í´ë”ì— ìˆëŠ” ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨/ì˜ˆì¸¡í•œ ê²°ê³¼ê°’.

## ğŸ“Œ ê°ì¢… parameter ì¡°ì ˆë²•

#### ğŸ”· hyperparameter

hyperparameter ì¡°ì ˆ ë°©ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
~~~
python main.py [ë°ì´í„°ì…‹ í´ë” ê²½ë¡œ] [hyperparameter ìˆ˜ì • ì˜µì…˜]
~~~
ì˜ˆì‹œ ì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
~~~
python main.py data/sample-classification --epochs 1200 --n-conv 5 --lr 0.03 
~~~

#### ğŸ”· node feature vector

node feature vectorì— ëŒ€í•œ ì •ë³´ëŠ” `atom_init.json` íŒŒì¼ì— ì €ì¥ë˜ì–´ ìˆë‹¤.
  
ë§Œì¼ node feature vectorë¥¼ ì¡°ì ˆí•˜ê³  ì‹¶ë‹¤ë©´, `encoding_feature_num.py`ë¥¼ ìˆ˜ì •í•˜ë©´ ëœë‹¤.  

7ë²ˆì§¸ ì¤„ë¶€í„° ë‚˜ì™€ìˆëŠ” feature list ì¤‘, ì‹¤ì œë¡œ node feature vectorì— í™œìš©í•˜ê³ ì í•˜ëŠ” featureë“¤ì„ ì„ íƒí•´ 12ë²ˆì§¸ ì¤„ì˜ feature setì— ì…ë ¥í•˜ë©´ ëœë‹¤.

`encoding_feature_num.py`ê°€ ìˆ˜ì •ë˜ë©´ ìë™ìœ¼ë¡œ `atom_init.json` íŒŒì¼ë„ ë®ì–´ì“°ê¸° ëª¨ë“œë¡œ ìˆ˜ì •ë˜ì–´ node vectorê°€ ì¡°ì ˆëœë‹¤.

#### ğŸ”· edge feature vector

`data.py` íŒŒì¼ì„ ìˆ˜ì •í•˜ë©´ edge vectorë¥¼ ì¡°ì ˆí•  ìˆ˜ ìˆë‹¤. 

`data.py`ì˜ 275~289ë²ˆì§¸ ì¤„ì—ì„œëŠ” edge vectorì™€ ê´€ë ¨ëœ hyperparameterë“¤ì„ ì„¤ëª…í•˜ê³  ìˆë‹¤.

~~~
- root_dir (str) : ì–´ë–¤ ë°ì´í„°ì…‹ í´ë”ë¥¼ ì‚¬ìš©í•  ê²ƒì¸ê°€
- max_num_nbr (int) : ê²°ì • ê·¸ë˜í”„ë¥¼ í˜•ì„±í•  ë•Œ ëª‡ ê°œì˜ ì´ì›ƒ ì›ìê¹Œì§€ë§Œ ì—°ê²°í•  ê²ƒì¸ê°€
- radius (float) : ì–¼ë§ˆì˜ ë°˜ì§€ë¦„ ì´ë‚´ì— ìˆëŠ” ì›ìë§Œ ì´ì›ƒ ì›ìë¡œ ì •ì˜í•  ê²ƒì¸ê°€
- dmin (float) : ë‘ ì›ì ì‚¬ì´ì˜ ê±°ë¦¬ê°€ ìµœì†Œ ì–¼ë§ˆ ì´ìƒì´ë¼ê³  ê°€ì •í•  ê²ƒì¸ê°€ (ê°€ìš°ì‹œì•ˆ ë²¡í„°í™”ë¥¼ ìœ„í•œ ìµœì†Œ ê¸¸ì´)
- step (float) : edge vectorë¥¼ ëª‡ ì¹¸ ê°„ê²©ìœ¼ë¡œ ìª¼ê°¤ ê²ƒì¸ê°€ (ê°€ìš°ì‹œì•ˆ basisì˜ ê°„ê²©) 
- random_seed (int) : ë°ì´í„°ë¥¼ ì„ì„ ë•Œ ê³ ì •í•˜ëŠ” ë‚œìˆ˜ì˜ ê°œìˆ˜
~~~

ì´ parameterë“¤ì„ ìˆ˜ì •í•˜ì—¬ edge vectorë¥¼ ì¡°ì ˆí•˜ë ¤ë©´ 300ë²ˆì§¸ ì¤„ì˜ ê°’ë“¤(radius,dmin, ..)ì„ ì¡°ì ˆí•˜ë©´ ëœë‹¤. (Gaussian distancing í˜•íƒœì˜ edge vector)

~~~
def __init__(self, root_dir, max_num_nbr=12, radius=8, dmin=0, step=0.2,
             random_seed=123):
~~~

## ğŸ“Œ Training by txie-93 github dataset

ìš°ì„  sample-regression í´ë”ì— ìˆëŠ” ì ì€ ìˆ˜ì˜ ë°ì´í„°ë¥¼ ê°€ì§€ê³  í›ˆë ¨í•´ë³¼ ê²ƒì´ë‹¤. 

ë‹¨ì§€ ì½”ë“œ ë™ì‘ì„ í™•ì¸í•˜ê¸° ìœ„í•´ êµ¬ì„±í•´ë†“ì€ datasetì´ê¸° ë•Œë¬¸ì—, sample-regressionê³¼ sample-classification í´ë”ì— ìˆëŠ” id_prop.csv íŒŒì¼ì˜ prop ê°’ë“¤ì€ ì‹¤ì œ ë¬¼ì„±ê°’ì´ ì•„ë‹Œ dummy ê°’ì´ë‹¤.

main.pyëŠ” 'cgcnn-master' í´ë”ì— ë“¤ì–´ìˆê¸° ë•Œë¬¸ì— ë‹¤ìŒê³¼ ê°™ì´ ì´ í´ë”ì˜ ê²½ë¡œì—ì„œ ì‹œì‘í•´ì•¼ í•œë‹¤.

~~~
(cgcnn) C:\Users\ingyeong\Desktop\Summer\cgcnn-master>
~~~

main.pyë¥¼ ì‹¤í–‰ì‹œí‚¬ ë•ŒëŠ” train, validation, testì˜ ratio í˜¹ì€ sizeì™€, ì–´ëŠ ê²½ë¡œì— ìˆëŠ” ë°ì´í„°ë¥¼ ì‚¬ìš©í• ì§€ë¥¼ ì§€ì •í•´ì£¼ë©´ ëœë‹¤. 

ì´ë•Œ ratioì™€ sizeëŠ” í˜¼ìš©í•˜ë©´ ì•ˆëœë‹¤.

~~~
python main.py --train-ratio 0.6 --val-ratio 0.2 --test-ratio 0.2 data/sample-regression
~~~
or
~~~
python main.py --train-size 6 --val-size 2 --test-size 2 data/sample-regression
~~~

í›ˆë ¨ì´ ëë‚˜ë©´ cgcnn-master í´ë”ì— `checkpoint.pth.tar`, `model_best.pth.tar`, ê·¸ë¦¬ê³  ê°ì¢… `.csv`íŒŒì¼ë“¤ì´ ì €ì¥ëœë‹¤. 

ì´ ê²°ê³¼ë“¤ì— ëŒ€í•´ì„œ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê³  ì‹¶ë‹¤ë©´, ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰ì‹œí‚¤ë©´ ëœë‹¤.
~~~
python draw_graph.py
~~~
ìƒì„±ëœ ê·¸ë˜í”„ë“¤ì€ cgcnn-master í´ë”ì— png íŒŒì¼ë¡œ ì €ì¥ëœë‹¤.

## ğŸ“Œ Predicting by txie-93 github dataset

Predictingì€ `predict.py` ì½”ë“œë¥¼ ì´ìš©í•˜ì—¬ ì§„í–‰ëœë‹¤. ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ë…¼ë¬¸ì— ë‚˜ì˜¤ëŠ” ë¯¸ë¦¬ í›ˆë ¨ëœ ëª¨ë¸ì¸ `pre-trained` datasetì„ í™œìš©í•  ê²ƒì´ë‹¤. ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” ë¬¼ì„±ì— ë”°ë¼ í•´ë‹¹í•˜ëŠ” í´ë”ë¥¼ ì‚¬ìš©í•˜ë©´ ëœë‹¤.

ì˜ˆë¥¼ ë“¤ì–´ `sample-regression` í´ë”ì— ìˆëŠ” ê²°ì •ì˜ formation energyë¥¼ ì˜ˆì¸¡í•˜ê³  ì‹¶ë‹¤ë©´, ë‹¤ìŒê³¼ ê°™ì´ ì½”ë“œë¥¼ ì‘ì„±í•˜ë©´ ëœë‹¤.

~~~
python predict.py pre-trained/formation-energy-per-atom.pth.tar. data/sample-regression
~~~

ë˜ë‹¤ë¥¸ ì˜ˆì‹œë¡œ 'sample-classification' í´ë”ì— ìˆëŠ” ê²°ì •ë“¤ì— ëŒ€í•´ ë°˜ë„ì²´ë©´ (0), ë„ì²´ë©´ (1)ë¡œ ì˜ˆì¸¡í•˜ê³  ì‹¶ë‹¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì½”ë“œë¥¼ ì‘ì„±í•˜ë©´ ëœë‹¤.

~~~
python predict.py pre-trained/semi-metal-classification.pth.tar. data/sample-classification
~~~

ì˜ˆì¸¡ì— ëŒ€í•œ ê²°ê³¼ ë°ì´í„°ë“¤ì€ `test_results.csv` íŒŒì¼ë¡œ ì €ì¥ëœë‹¤.

## ğŸ“Œ Training by google drive dataset

txie-93 githubì—ì„œ ì œê³µí•˜ëŠ” ìƒ˜í”Œ ë°ì´í„°ì…‹ì€ í¬ê¸°ê°€ ë§¤ìš° ì‘ê¸°ë•Œë¬¸ì—, KISTì˜ ê¹€ë™í›ˆ ë°•ì‚¬ë‹˜ì´ customized datasetì„ êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì œê³µí•˜ê³  ìˆë‹¤. 

`data` í´ë”ì— ë“¤ì–´ìˆëŠ” 'data_' ì´ë¦„ì˜ í•˜ìœ„ í´ë”ë“¤ì´ ì „ë¶€ customized datasetì— í•´ë‹¹í•œë‹¤. 

í´ë”ëª…ì—ëŠ” ê°ê° í•™ìŠµí•˜ê³ ì í•˜ëŠ” ë¬¼ì„±ê³¼ cif íŒŒì¼ì˜ ê°œìˆ˜ê°€ ì“°ì—¬ìˆê³ , bandgap í•™ìŠµìš© ë°ì´í„°ì…‹ì€ metalê³¼ non-metalì˜ cif íŒŒì¼ ê°œìˆ˜ê°€ 1:1 ë¹„ìœ¨ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.
  
í›ˆë ¨ì€ ì´ì „ì— ì§„í–‰í•œ ê²ƒê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•˜ë©´ ëœë‹¤.

~~~
python main.py --train-ratio 0.6 --val-ratio 0.2 --test-ratio 0.2 data/data_regression_formE_1000
~~~

ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ëŠ” ì½”ë“œ ë˜í•œ ë™ì¼í•˜ë‹¤.
~~~
python draw_graph.py
~~~
